{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From poll to Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import json \n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName('poll_to_idxs')\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory where to access the poll\n",
    "poll_dir = \"../data/poll_data.csv\"\n",
    "\n",
    "# Load the csv poll as a dataframe\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    # .option(\"encoding\", \"UTF-8\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(poll_dir)\n",
    ")\n",
    "\n",
    "# List of columns that will not be considered individually scored (due to not be used in the calculation)\n",
    "skip_cols = [\n",
    "    \"Ho letto e accettato l'informativa e confermo inoltre di avere più di 18 anni\",\n",
    "    \"Informazioni cronologiche\",\n",
    "    \"Quanti anni hai?\",\n",
    "    \"Genere\",\n",
    "    \"Da quante persone è composto il tuo nucleo familiare?\",\n",
    "    \"Occupazione\",\n",
    "    \"Quanto è grande la tua azienda?\",\n",
    "    \"Da che regione provieni?\",\n",
    "    \"Provincia di provenienza\",\n",
    "    \"In che regione lavori/studi?\",\n",
    "    \"Provincia del luogo di lavoro/studio\",\n",
    "    \"Invalidità\",\n",
    "    \"Tipo di residenza\",\n",
    "    \"Numero di persone con cui convivi\",\n",
    "    \"Entrate Familiari Mensili Nette\",\n",
    "    \"Entrate Personali Mensili Nette \",\n",
    "]\n",
    "\n",
    "# Load the questions json\n",
    "with open(\"../data/questions.json\", \"r\", encoding=\"utf-8\") as questions_file:\n",
    "    questions = json.load(questions_file)\n",
    "\n",
    "# Create a question_text:question_idx map, useful to alias the columns\n",
    "questions_idxs = {questions[q][\"question_text\"]: q for q in questions.keys()}\n",
    "\n",
    "# Alias the columns (long column names cause bugs and are hard to use)\n",
    "for k, v in questions_idxs.items():\n",
    "    df = df.withColumnRenamed(k, v)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Subtract\" the list of unscorable cols from the list of scorable cols\n",
    "scorable_cols = [item for item in df.columns if item not in skip_cols]\n",
    "\n",
    "# Iterate over the scorable columns to create the scores dictionary\n",
    "scores = {}\n",
    "for col in scorable_cols:\n",
    "    # Shortcuts for some useful values\n",
    "    question_type = questions[col][\"question_type\"]\n",
    "    question_score = questions[col][\"question_score\"]\n",
    "    question_answers = questions[col][\"answers\"]\n",
    "\n",
    "    # Skip unscored questions\n",
    "    if len(question_answers) == 0 and question_type != \"comma_separated\":\n",
    "        continue\n",
    "\n",
    "    # Collect the Row values for the current column and access its value (index 0)\n",
    "    answers = [str(d[0]) for d in df.select(col).collect()]\n",
    "\n",
    "    # Handle score computation differently based on question_type\n",
    "    row_scores = []\n",
    "    if question_type in [\"basic\", \"multivalue\"]:\n",
    "        for indexes_cols_df in answers:\n",
    "            row_scores.append(question_answers[indexes_cols_df][\"answer_score\"] * question_score)\n",
    "\n",
    "        scores[col] = row_scores\n",
    "\n",
    "    elif question_type == \"comma_separated\":\n",
    "        for i in answers:\n",
    "            row_scores.append(len(i.split(\";\")))\n",
    "\n",
    "        scores[col] = row_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scores dataframe from the scores dictionary\n",
    "df_scores = spark.createDataFrame(pd.DataFrame(scores))\n",
    "df_scores.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indexes dictionary, which will be used to compute the indexes dataframe\n",
    "indexes_cols = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the indexes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purchases indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purchases indexes calculation\n",
    "df_s = df_scores.select([f\"S_{d}\" for d in range(1, 10)]).collect()\n",
    "\n",
    "# i_S_col\n",
    "i_S_col = []\n",
    "for s in df_s:\n",
    "    i_S_col.append(sum([val for val in s]) / 1450)\n",
    "indexes_cols[\"i_S\"] = i_S_col\n",
    "\n",
    "\n",
    "col_S_1 = df.select(\"S_1\").collect()\n",
    "S_1 = []\n",
    "answer1 = questions[\"S_1\"][\"answers\"]\n",
    "for i in range(len(col_S_1)):\n",
    "    s1 = col_S_1[i][0]\n",
    "    for j in answer1.keys():\n",
    "        if s1 == j:\n",
    "            val = answer1[j][\"answer_score_1\"]\n",
    "            S_1.append(val)\n",
    "            break\n",
    "\n",
    "col_S_2 = df.select(\"S_2\").collect()\n",
    "S_2 = []\n",
    "answer2 = questions[\"S_2\"][\"answers\"]\n",
    "for i in range(len(col_S_2)):\n",
    "    s2 = str(col_S_2[i][0])\n",
    "    for j in answer2.keys():\n",
    "        if s2 == j:\n",
    "            val = answer2[j][\"answer_score_1\"]\n",
    "            S_2.append(val)\n",
    "            break\n",
    "        \n",
    "df_s1 = df_scores.select([f\"S_{d}\" for d in range(3, 10)]).collect()\n",
    "i_tot_S_col = []\n",
    "k = 0  # variabile temporanea per accedere agli elementi di S_1 ed S_2 ed effettuare il rapporto\n",
    "for s_1 in df_s1:\n",
    "    somma = sum([val1 for val1 in s_1])\n",
    "    r = S_2[k] / S_1[k]\n",
    "    i_tot_S_col.append(somma * r)\n",
    "    k += 1\n",
    "indexes_cols[\"i_tot_S\"] = i_tot_S_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo indici domande relative al Vestiario\n",
    "df_v = df_scores.select([f\"V_{d}\" for d in range(10, 13)]).collect()\n",
    "\n",
    "i_V_col = []\n",
    "for v in df_v:\n",
    "    i_V_col.append(sum([val for val in v]) / 550)\n",
    "\n",
    "indexes_cols[\"i_V\"] = i_V_col\n",
    "\n",
    "col_V_10 = df.select(\"V_10\").collect()\n",
    "V_10 = []\n",
    "answer10 = questions[\"V_10\"][\"answers\"]\n",
    "for i in range(len(col_V_10)):\n",
    "    v10 = str(col_V_10[i][0])\n",
    "    for j in answer10.keys():\n",
    "        if v10 == j:\n",
    "            val = answer10[j][\"answer_score_1\"]\n",
    "            V_10.append(val)\n",
    "            break\n",
    "df_v1 = df_scores.select([f\"V_{d}\" for d in range(11, 13)]).collect()\n",
    "i_tot_V_col = []\n",
    "l = 0  # variabile temporanea per accedere agli elementi di V_10\n",
    "for v1 in df_v1:\n",
    "    somma1 = sum([val1 for val1 in v1]) / 400\n",
    "    i_tot_V_col.append(somma1 * V_10[l])\n",
    "    l += 1\n",
    "indexes_cols[\"i_tot_V\"] = i_tot_V_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo indici domande relative alla Casa\n",
    "df_c = df_scores.select([f\"C_{d}\" for d in range(13, 15)]).collect()\n",
    "\n",
    "i_C_col = []\n",
    "for c in df_c:\n",
    "    i_C_col.append(sum([val for val in c]) / 350)\n",
    "\n",
    "indexes_cols[\"i_C\"] = i_C_col\n",
    "\n",
    "i_tot_C_col = []\n",
    "for c1 in df_c:\n",
    "    if c1[1] == 0:\n",
    "        i_tot_C_col.append(c1[0] / 150)\n",
    "    else:\n",
    "        i_tot_C_col.append(c1[0] / c1[1])\n",
    "indexes_cols[\"i_tot_C\"] = i_tot_C_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo indice Educazione e Ricerca\n",
    "df_e = df_scores.select([f\"ER_{d}\" for d in range(1, 4)]).collect()\n",
    "i_ER_col = []\n",
    "for e in df_e:\n",
    "    i_ER_col.append(sum([val for val in e]) / 500)\n",
    "indexes_cols[\"i_ER\"] = i_ER_col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobility indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m1 = df_scores.select([\"m_8\", \"m_9\"]).collect()\n",
    "\n",
    "i_m1_col = []\n",
    "for s in df_m1:\n",
    "    m_8, m_9 = s[0], s[1]\n",
    "    i_m1_col.append(m_9 / m_8)\n",
    "\n",
    "indexes_cols[\"i_M1\"] = i_m1_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m2 = df_scores.select([\"m_17\", \"m_18\"]).collect()\n",
    "\n",
    "i_m2_col = []\n",
    "for s in df_m2:\n",
    "    m_17, m_18 = s[0], s[1]\n",
    "    i_m2_col.append(m_18 / m_17)\n",
    "\n",
    "indexes_cols[\"i_M2\"] = i_m2_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_size_col_label = \"Da quante persone è composto il tuo nucleo familiare?\"\n",
    "\n",
    "df_m3 = df_scores.select([\"m_8\"]).collect()\n",
    "df_fam = df.select([fam_size_col_label]).collect()\n",
    "\n",
    "i_m3_col = []\n",
    "for s in df_m3:\n",
    "    m_8, f = s[0], int(df_fam[0][0])\n",
    "    i_m3_col.append(m_8 / f)\n",
    "\n",
    "indexes_cols[\"i_M3\"] = i_m3_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m4 = df_scores.select([\"m_11\", \"m_12\", \"m_13\"]).collect()\n",
    "\n",
    "i_m4_col = []\n",
    "for s in df_m4:\n",
    "    m_11, m_12, m_13 = s[0], s[1], s[2]\n",
    "    i_m4_col.append(m_12 / (m_11 + m_12 + m_13))\n",
    "\n",
    "indexes_cols[\"i_M4\"] = i_m4_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m5 = df_scores.select([\"m_20\"]).collect()\n",
    "\n",
    "i_m5_col = []\n",
    "for s in df_m5:\n",
    "    m_20 = s[0]\n",
    "    i_m5_col.append(m_20)\n",
    "\n",
    "indexes_cols[\"i_M5\"] = i_m5_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m6 = df_scores.select([\"m_19\"]).collect()\n",
    "\n",
    "i_m6_col = []\n",
    "for s in df_m6:\n",
    "    m_19 = s[0]\n",
    "    i_m6_col.append(m_19)\n",
    "\n",
    "indexes_cols[\"i_M6\"] = i_m6_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m7 = df_scores.select([\"m_4\", \"m_5\"]).collect()\n",
    "\n",
    "i_m7_col = []\n",
    "for s in df_m7:\n",
    "    m_4, m_5 = s[0], s[1]\n",
    "    i_m7_col.append(m_5 / m_4)\n",
    "\n",
    "indexes_cols[\"i_M7\"] = i_m7_col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systems (home)\n",
    "df_e1 = df_scores.select([\"eh2\"]).collect()\n",
    "i_e1_col = []\n",
    "for s in df_e1:\n",
    "    i_e1_col.append(s[0] / 5)\n",
    "indexes_cols[\"i_e1\"] = i_e1_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systems (work)\n",
    "df_e2 = df_scores.select([\"ew2\"]).collect()\n",
    "i_e2_col = []\n",
    "for s in df_e2:\n",
    "    i_e2_col.append(s[0] / 5)\n",
    "indexes_cols[\"i_e2\"] = i_e2_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustainable Source (home)\n",
    "df_e3 = df_scores.select([\"eh3\", \"eh4\"]).collect()\n",
    "i_e3_col = []\n",
    "for s in df_e3:\n",
    "    eh3, eh4 = s[0], s[1]\n",
    "    i_e3_col.append(eh3 * eh4)\n",
    "indexes_cols[\"i_e3\"] = i_e3_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustainable Source (work)\n",
    "df_e4 = df_scores.select([\"ew3\", \"ew4\"]).collect()\n",
    "i_e4_col = []\n",
    "for s in df_e4:\n",
    "    ew3, ew4 = s[0], s[1]\n",
    "    i_e4_col.append(ew3 * ew4)\n",
    "indexes_cols[\"i_e4\"] = i_e4_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiency Ratio\n",
    "df_e5 = df_scores.select([\"eh1\", \"eh5\"]).collect()\n",
    "i_e5_col = []\n",
    "for s in df_e5:\n",
    "    eh1, eh5 = s[0], s[1]\n",
    "    i_e5_col.append(eh1 / eh5)\n",
    "indexes_cols[\"i_e5\"] = i_e5_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GreenBuilding (home)\n",
    "df_e6 = df_scores.select([\"eh6\"]).collect()\n",
    "i_e6_col = []\n",
    "for s in df_e6:\n",
    "    i_e6_col.append(s[0] / 6)\n",
    "indexes_cols[\"i_e6\"] = i_e6_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GreenBuilding (work)\n",
    "df_e7 = df_scores.select([\"ew5\"]).collect()\n",
    "i_e7_col = []\n",
    "for s in df_e7:\n",
    "    i_e7_col.append(s[0] / 6)\n",
    "indexes_cols[\"i_e7\"] = i_e7_col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water (home)\n",
    "df_water1 = df_scores.select([\"wh1\", \"wh2\", \"wh3\", \"wh4\"]).collect()\n",
    "i_e8_col = []\n",
    "for s in df_water1:\n",
    "    wh1, wh2, wh3, wh4 = s[0], s[1], s[2], s[3]\n",
    "    i_e8_col.append((wh1 + wh2 + wh3 + wh4) / 4)\n",
    "indexes_cols[\"i_e8\"] = i_e8_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water (work)\n",
    "df_water2 = df_scores.select([\"ww1\", \"ww2\", \"ww3\", \"ww4\"]).collect()\n",
    "i_e9_col = []\n",
    "for s in df_water2:\n",
    "    ww1, ww2, ww3, ww4 = s[0], s[1], s[2], s[3]\n",
    "    i_e9_col.append((ww1 + ww2 + ww3 + ww4) / 4)\n",
    "indexes_cols[\"i_e9\"] = i_e9_col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waste Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waste (home)\n",
    "df_waste1 = df_scores.select([\"wasteh1\", \"wasteh2\", \"wasteh3\", \"wasteh4\"]).collect()\n",
    "i_e10_col = []\n",
    "for s in df_waste1:\n",
    "    wasteh1, wasteh2, wasteh3, wasteh4 = s[0], s[1], s[2], s[3]\n",
    "    i_e10_col.append((wasteh1 + wasteh2 + wasteh3 + wasteh4) / 4)\n",
    "indexes_cols[\"i_e10\"] = i_e10_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waste (work)\n",
    "df_waste2 = df_scores.select([\"wastew1\", \"wastew2\", \"wastew3\", \"wastew4\"]).collect()\n",
    "i_e11_col = []\n",
    "for s in df_waste1:\n",
    "    wastew1, wastew2, wastew3, wastew4 = s[0], s[1], s[2], s[3]\n",
    "    i_e11_col.append((wastew1 + wastew2 + wastew3 + wastew4) / 4)\n",
    "indexes_cols[\"i_e11\"] = i_e11_col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in indexes_cols.keys():\n",
    "    indexes_cols[k] = [round(e, 2) for e in indexes_cols[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_cols_df = pd.DataFrame(indexes_cols)\n",
    "\n",
    "indexes_max = {\n",
    "    # \"i_S\": None,\n",
    "    #\"i_tot_S\": None,\n",
    "    # \"i_V\": None,\n",
    "    # \"i_C\": None,\n",
    "    # \"i_ER\": None,\n",
    "    # \"i_M1\": 1,\n",
    "    # \"i_M3\": None,\n",
    "    # \"i_M7\": None,\n",
    "    \"i_tot_V\": 5,\n",
    "    \"i_tot_C\": 1.5,\n",
    "    \"i_M2\": 1,\n",
    "    \"i_M4\": 0.95,\n",
    "    \"i_M5\": 100,\n",
    "    \"i_M6\": 100,\n",
    "    \"i_e1\": 1,\n",
    "    \"i_e2\": 1,\n",
    "    \"i_e3\": 5,\n",
    "    \"i_e4\": 5,\n",
    "    \"i_e5\": 1/0.015,\n",
    "    \"i_e6\": 1,\n",
    "    \"i_e7\": 1,\n",
    "    \"i_e8\": 200,\n",
    "    \"i_e9\": 200,\n",
    "    \"i_e10\": 200,\n",
    "    \"i_e11\": 200,\n",
    "}\n",
    "\n",
    "for c in indexes_cols_df.columns:\n",
    "    val = indexes_cols_df[c] / indexes_max.get(c, indexes_cols_df[c].max())\n",
    "    indexes_cols_df[c] = round(val, 3)\n",
    "\n",
    "# create the indexes dataframe from the indexes dictionary\n",
    "df_indexes = spark.createDataFrame(pd.DataFrame(indexes_cols_df))\n",
    "df_indexes.show(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_indexes.toPandas()\n",
    "\n",
    "vectors = []\n",
    "for _, r in df_features.iterrows():\n",
    "    values = []\n",
    "    for i in range(len(df_features.columns)):\n",
    "        values.append(r[i])\n",
    "\n",
    "    vectors.append(Vectors.dense(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = spark.createDataFrame(pd.DataFrame({\"features\":vectors}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = [i for i in range(indexes_cols_df.shape[0])]\n",
    "\n",
    "rows = []\n",
    "for i in user_id:\n",
    "    for index,c in enumerate(indexes_cols_df):\n",
    "        rows.append((i, index, indexes_cols_df.iloc[i][index]))\n",
    "\n",
    "cf_df = pd.DataFrame(rows, columns=[\"user_id\", \"feature_id\", \"value\"])\n",
    "\n",
    "\n",
    "cf_df = spark.createDataFrame(cf_df)\n",
    "cf_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = cf_df\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(\n",
    "    maxIter=5, \n",
    "    regParam=0.01, \n",
    "    userCol=\"user_id\", \n",
    "    itemCol=\"feature_id\", \n",
    "    ratingCol=\"value\",\n",
    "    coldStartStrategy=\"drop\",\n",
    ")\n",
    "\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"value\",\n",
    "    predictionCol=\"prediction\",\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctured_df = indexes_cols_df\n",
    "celle_el = []\n",
    "c = 1\n",
    "while c <= 130:\n",
    "    i = random.randint(0,51)\n",
    "    j = random.randint(0,24)\n",
    "    cel = (i,j)\n",
    "    if cel in celle_el:\n",
    "        continue\n",
    "    else:\n",
    "        punctured_df.iloc[i,j] = None\n",
    "        celle_el.append(cel)\n",
    "        c += 1\n",
    "print(celle_el)\n",
    "print(len(celle_el))\n",
    "punctured_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = [i for i in range(punctured_df.shape[0])]\n",
    "\n",
    "rows = []\n",
    "for i in user_id:\n",
    "    for index,c in enumerate(punctured_df):\n",
    "        rows.append((i, index, punctured_df.iloc[i][index]))\n",
    "\n",
    "punctured_cf_df = pd.DataFrame(rows, columns=[\"user_id\", \"feature_id\", \"value\"])\n",
    "\n",
    "\n",
    "punctured_cf_df = spark.createDataFrame(punctured_cf_df)\n",
    "punctured_cf_df.show(1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = punctured_cf_df\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "training.show()\n",
    "print(\"--------------\")\n",
    "test.show()\n",
    "\n",
    "\n",
    "FUNZIONE PER DETERMINARE COME SETTARE I PARAMETRI DEL MODELLO (????????)\n",
    "def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):\n",
    "    \"\"\"\n",
    "    grid search function to select the best model based on RMSE of\n",
    "    validation data\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    validation_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    maxIter: int, max number of learning iterations\n",
    "    \n",
    "    regParams: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    ranks: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The best fitted ALS model with lowest RMSE score on validation data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in regParams:\n",
    "            # get ALS model\n",
    "            als = ALS().setMaxIter(maxIter).setRank(rank).setRegParam(reg)\n",
    "            # train ALS model\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"rating\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: '\n",
    "                  'validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and '\n",
    "          'regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model\n",
    "M = tune_ALS(training, test, 10, 1.0, )\n",
    "print(M)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(\n",
    "    maxIter=10, \n",
    "    regParam=1.0, \n",
    "    userCol=\"user_id\", \n",
    "    itemCol=\"feature_id\", \n",
    "    ratingCol=\"value\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"value\",\n",
    "    predictionCol=\"prediction\",\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=3)\n",
    "\n",
    "kmeans.setSeed(1)\n",
    "# kmeans.setWeightCol(\"weigh_col\")\n",
    "kmeans.setMaxIter(10)\n",
    "kmeans.getMaxIter()\n",
    "kmeans.clear(kmeans.maxIter)\n",
    "kmeans.getSolver()\n",
    "\n",
    "model = kmeans.fit(df_vectors)\n",
    "\n",
    "model.getMaxBlockSizeInMB()\n",
    "model.getDistanceMeasure()\n",
    "model.setPredictionCol(\"prediction\")\n",
    "model.predict(df_vectors.head().features)\n",
    "\n",
    "centers = model.clusterCenters()\n",
    "len(centers)\n",
    "\n",
    "transformed = model.transform(df_vectors).select(\"features\", \"prediction\")\n",
    "rows = transformed.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_features.corr(), cmap=\"crest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 100, 'display.max_columns', 100):\n",
    "    display(df_features.corr()[df_features.corr() >= 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features.plot.scatter('i_S', 'i_tot_S', alpha=0.2)\n",
    "# df_features.plot.scatter('i_C', 'i_tot_C', alpha=0.2)\n",
    "# df_features.plot.scatter('i_V', 'i_tot_V', alpha=0.2)\n",
    "# df_features.plot.scatter('i_e8', 'i_e3', alpha=0.2)\n",
    "# df_features.plot.scatter('i_e7', 'i_e6', alpha=0.2)\n",
    "# df_features.plot.scatter('i_e9', 'i_e8', alpha=0.2)\n",
    "\n",
    "#    casa  i_e_1, i_e_3, i_e_6\n",
    "#  lavoro  i_e_2, i_e_4, i_e_7\n",
    "\n",
    "\n",
    "scatter_matrix(df_features[['i_e1', 'i_e3', 'i_e6', 'i_e2', 'i_e4', 'i_e7']], diagonal='kde')\n",
    "scatter_matrix(df_features[['i_e1', 'i_e3', 'i_e6', 'i_e2', 'i_e4', 'i_e7']], diagonal='hist')\n",
    "\n",
    "scatter_matrix(df_features[['i_e8', 'i_e9', 'i_e10', 'i_e11']], diagonal='kde')\n",
    "scatter_matrix(df_features[['i_e8', 'i_e9', 'i_e10', 'i_e11']], diagonal='hist')\n",
    "\n",
    "scatter_matrix(df_features[['i_S', 'i_tot_S', 'i_V', 'i_tot_V', 'i_C', 'i_tot_C']], diagonal='kde')\n",
    "scatter_matrix(df_features[['i_S', 'i_tot_S', 'i_V', 'i_tot_V', 'i_C', 'i_tot_C']], diagonal='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots()\n",
    "pyplot.xlabel('casa')\n",
    "pyplot.ylabel('lavoro')\n",
    "ax.scatter(df_features['i_e8'], df_features['i_e9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.hasSummary)\n",
    "summary = model.summary\n",
    "print(summary.k)\n",
    "print(summary.clusterSizes)\n",
    "\n",
    "summary.cluster.show(52)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
